---
title: "Summary Report of Regression On Real Estate dataset"
author: | 
    |     Achal, Gupta ---------------A00258772
date: "5 April 2019"
output: html_document
editor_options: 
  chunk_output_type: inline
---
#Data Set Information:
The market historical data set of real estate valuation are collected from Sindian Dist., New Taipei City, Taiwan. The real estate valuation is a regression problem. The data set was randomly split into the training data set (2/3 samples) and the testing data set (1/3 samples). <br>

#Attribute Information
The inputs are as follow: <br>
X1= **TranDate: **the transaction date (for example, 2013.250=2013 March, 2013.500=2013 June, etc.) <br>
X2= **Age: **the house age (unit: year) <br>
X3= **MRTDist: **the distance to the nearest MRT station (unit: meter) <br>
X4= **NoStores: **the number of convenience stores in the living circle on foot (integer) <br>
X5= **Lat: **the geographic coordinate, latitude. (unit: degree) <br>
X6= **Long: **the geographic coordinate, longitude. (unit: degree) <br>

The output is as follow: <br>
Y= **Y_HousePrice: **house price of unit area (10000 New Taiwan Dollar/Ping, where Ping is a local unit, 1 Ping = 3.3 meter squared) <br>



```{r packagesLibrary, include=FALSE, warning = FALSE, message = FALSE}
###IMPORTING LIBRARIES
#Below code will import all the required libraries.
library(psych)
library(caret)
library(dplyr)
library(tidyverse)
library(ggplot2)
```

```{r dataAcquisition, include=FALSE, warning = FALSE}
###DATA ACCQUISTION
#Below code will import the data present in CSV format into R and store it in a Data Frame.
RealEstate <- read.csv("Data/Real estate valuation data set.csv", header = T)

#View the data
head(RealEstate,5)
```

```{r dataCleaning, include=FALSE, warning = FALSE, tidy = TRUE}
###DATA CLEANING
#### Renaming Columns
#Below code will rename Column names in Data Frame

colnames(RealEstate) <- c('Id','TranDate','Age','MRTDist', 'NoStores'
                     ,'Lat', 'Long', 'Y_HousePrice')


#View the structure of data
str(RealEstate)

#Notice transaction date is in Numeric format, converting it to date
RealEstate$TranDate <- as.Date(RealEstate$TranDate, origin = "1900-01-01")

#Verify the structure of data
str(RealEstate)

### Descriptive Analysis
#Exploring the data and gather some insights!

#Duplicating data set for exploration analysis, we will create some new columns and don't want to alter original data frame
RealEstate_Explore <- RealEstate
```

### Average House price in Euros per square metre?
```{r convertUnit, include=FALSE, warning = FALSE, tidy = TRUE}
#Original Data is given in 10000 New Taiwan Dollar/Ping. 

#Assuming average conversion rate 1NT$ = 0.028 Euros and 1 ping = 3.30 sq meter.
#Below code will convert House Price as required and store values into a new column. And Later calculate the average of that column
convFact <- ((10000 * 0.028)/3.30)
RealEstate_Explore$PriceEuroPerSqM <- RealEstate_Explore$Y_HousePrice * convFact 
mean_All <- mean(RealEstate_Explore$PriceEuroPerSqM)
```

The average House price in Euros Per Sq Metre is: <br>
**`r mean_All`**

### Are houses near(within 1KM radius) MRT station more expensive?
```{r include=FALSE, warning = FALSE, tidy = TRUE}
#Note - Original distance is given in meters.
#Below code will first filter out houses which are less than 1 KM away from MRT station and then calculate average of the prices for those houses.
RealEstate_Less1KM <- RealEstate_Explore %>% 
  filter(RealEstate_Explore$MRTDist<1000)
mean_Less1KM <- mean(RealEstate_Less1KM$PriceEuroPerSqM)
```
The average House price in Euros Per Sq Meter where distance to nearest MRT is less than 1KM is: <br>
**`r mean_Less1KM`**

The difference between both averages in Euros is: <br>
**`r mean_Less1KM - mean_All`**

##Visualizing the House Prices and Distance from MRT station using a scatter plot
```{r echo=FALSE, warning=FALSE, tidy=TRUE}
ggplot(data = RealEstate_Explore, aes(x = MRTDist, y = PriceEuroPerSqM)) +
  geom_point()  +
  theme(panel.background = element_rect(fill = "white"),
        axis.line.x=element_line(),
        axis.line.y=element_line()) +
  ggtitle("Distance from MRT Station Vs House Prices") +
  xlab("Distance from Nearest MRT station(Metres)") + 
  ylab("House Price (Euros Per Sq Metres)")

```
<br>
Scatter plot clearly shows that <b>houses closer to MRT stations have comparatively higher prices.</b> Hence the houses near MRT station have higher price on an average than overall city average. <br>

##visualizing the House Prices and age of the house using a scatter plot
### Does age of the house relates to the price of the house?
```{r echo=FALSE, warning=FALSE, tidy=TRUE}
ggplot(data = RealEstate_Explore, aes(x = Age, y = PriceEuroPerSqM)) +
  geom_point()  +
  theme(panel.background = element_rect(fill = "white"),
        axis.line.x=element_line(),
        axis.line.y=element_line()) +
  ggtitle("Age of the Vs House Prices") +
  xlab("Age of the House") + 
  ylab("House Price (Euros Per Sq Metres)")
```
</br>
Scatter plot clearly shows that <b> age of the house is not related to the price of house. </b>Hence the house price is not affected by the age of the house.

### Age of the top 5 costliest properties which are not newly built

```{r include=FALSE, warning = FALSE, tidy = TRUE}
#Below code will filter out houses whose Age > 0 and then sort them in ascending order
Costliest_Estate <- RealEstate_Explore %>% 
  filter(Age > 0) %>% 
  arrange(Y_HousePrice)
```

```{r echo=FALSE, warning=FALSE, tidy=TRUE}
barplot(tail(Costliest_Estate$Age,5),
        names.arg=tail(Costliest_Estate$Id,5),
        col = ("gold1"),
        border = ("goldenrod2"),
        main="Age of Top 5 Non-Newly Built Costliest Houses", 
        xlab="Esatate ID",
        ylab="HOuse Price"
        )
```


### Regression Analysis
```{r include=FALSE, warning = FALSE, tidy = TRUE}
####Creating Subset
#Create a subset with only required columns for the regression

RealEstate_Norm_sub <- RealEstate%>% 
  select(Age:Y_HousePrice)
```

####Analyse Output/Predictor column
Box plot of the House Prices

```{r echo=FALSE, warning=FALSE, tidy=TRUE}
boxplot(RealEstate_Norm_sub$Y_HousePrice)
```

**Note:** there are few outliers, performing further analysis on whether to remove outlier or not.

#### Plotting a scatterplot with regression line to visualize position of outlier

```{r echo=FALSE, warning=FALSE, tidy=TRUE}
scatter.smooth(RealEstate_Norm_sub$Y_HousePrice, ylab= "House Prices")

```
</br>
```{r include=FALSE, warning = FALSE, tidy = TRUE}
#Calculate the **Adjusted Rsquare** value for the regression model before removing any outlier.
rSquare1 <- round(summary(lm(Y_HousePrice ~ ., data =RealEstate_Norm_sub))$adj.r.squared, 3)
```
Scatterplot clearly shows the outlier will not impact the regression line but will only increase the residuals and can be removed. </br>
Adjusted r square is **`r rSquare1 ` **which suggest its not a great model

```{r include=FALSE, warning = FALSE, tidy = TRUE}
#Removing the house with exceptionally high price and recalculating the r square value.
RealEstate_Norm_sub <- RealEstate_Norm_sub[-which.max(RealEstate_Norm_sub$Y_HousePrice),]
rSquare2 <- round(summary(lm(Y_HousePrice ~ ., data =RealEstate_Norm_sub))$adj.r.squared,3)
```

Adjusted r square for the model is greatly increased from **`r rSquare1`** to **`r rSquare2`** and hence removal of the record was correct decision.

#### Visualizing the scatterplot again to verify the regression line.
```{r echo=FALSE, warning=FALSE, tidy=TRUE}
scatter.smooth(RealEstate_Norm_sub$Y_HousePrice, ylab= "House Prices")
```
</br>Slope of regression is line not impacted. </br>

####Correlation among various columns
Graph below will perform three analysis: </br>
1. Distribution of data for each feature or column shown using a histogram.</br>
2. Correlation coefficients for each combination of feature</br>
3. Scatterplot with fit line to visualize correlation</br>

```{r include=FALSE, warning=FALSE, tidy=TRUE}
pairs.panels(RealEstate_Norm_sub)
```

<b> Key Observations: </b> </br>
1. Age does not show a strong relation with any of the feature and hence must be included in model.</br>
2. Distance from nearest MRT station is highly correlated with latitude and longitude.</br>


```{r include=FALSE, warning = FALSE, tidy = TRUE}
#### Splitting data into training and test datasets.
set.seed(123)
training.samples <- RealEstate_Norm_sub$Y_HousePrice %>% 
  createDataPartition(p = 0.8, list = FALSE)
train.data  <- RealEstate_Norm_sub[training.samples, ]
test.data <- RealEstate_Norm_sub[-training.samples, ]
```


#### Hypotheis
<b>NULL Hypothesis H0:</b> There is no relationship between Dependent and Independent variables</br>
<b>Alternate Hypothesis H1:</b> There is a relationship between Dependent and Independent variables</br>


#### Initial Model
Creating a regression model first using all columns and view the adjusted r squared statistics for the model.
```{r include=FALSE, warning = FALSE, tidy = TRUE}
priceModel <- lm(Y_HousePrice ~ ., data =train.data)
rSquare3 <- round(summary(priceModel)$adj.r.squared,3)
```
Adjusted r squared (**`r rSquare3`**) is bit low, the more the value of adjusted r square better will be the model.

### MODEL OPTIMIZATION
#### Adding Non Linear Relationships
By default linear regression assumes linear relationship, which is not the case for each feature. For example age of the house can have a non linear relationship. (Optimizing the model and then taking a deeper look into various model statistics.)
```{r include=FALSE, warning = FALSE, tidy = TRUE}
train.data$Age_2 <- train.data$Age^2
test.data$Age_2 <- test.data$Age^2
```

#### Step Backward Optimization
```{r echo=FALSE, warning=FALSE, tidy=TRUE}
priceModel_step <- step(priceModel, direction = "backward")
priceModel_step <- lm(formula = Y_HousePrice ~ Age + MRTDist + 
     NoStores + Lat + Age_2, 
   data = train.data)
```
```{r include=FALSE, warning = FALSE, tidy = TRUE}
rSquare4 <- round(summary(priceModel_step)$adj.r.squared,3)
```
Increase in Adjusted R squared value(**`r rSquare4`**) signifies an increase in accuracy of the model.
Further improving accuracy by taking into account interactions.

#### Adding Interactions and Non Linear relationship for enhanced model
There is a possibility of interaction between location of house (latitude and longitude) and distance from MRT station and hence taking interactions into account.
```{r include=FALSE, warning=FALSE, tidy=TRUE}
priceModel_enhanced <- lm(Y_HousePrice ~ Age + Age_2 + MRTDist*Lat*Long + NoStores  , data =train.data)
```
```{r echo=FALSE, warning = FALSE, tidy = TRUE}
summary(priceModel_enhanced)
```
Increase in <b>Adjusted r squared</b> value indicates the improvement in model performance</br>
Also, overall <b>p-value</b> (less than 0.05) shows null hypothesis can be rejected and hence house price can be predicted using various columns.</br>
<b>F-Statistic</b> represent the relation between dependent and independent variable, higher the value stronger the relationship</br>
Above summary shows the features were significant in predicting House Prices. **Three stars**
shows highly significant features while two or less stars shows less significant features.

### Understanding Summary in detail
Understanding each part of the summary in more details.</br>

#### Is Hypothesis supported?
```{r echo=FALSE, warning = FALSE, tidy = TRUE}
summary(priceModel_enhanced)$coefficients
```
Output shows equation coefficients for each feature 

First row shows the intercept or constant of the equation</br>
Next rows represent the slope of equation for each of the feature used in regression.

Various Columns represent following information.</br>
<b> Estimate:</b> Expected value for the slope of feature and intercept of the equation.</br>
<b> Std. Error:</b> Average variation from expected value</br>
<b> t value:</b> Statistics to show how many SD the estimated coefficient is from 0</br>
<b> Pr(>|t|):</b> p-Value, using 95% CI, if p-value is less than 0.05 reject null hypothesis</br>

It can be observed that p-value (less than 0.05) and all columns are significant in predicting house prices.
  

#### How well model fits the data?
```{r echo=FALSE, warning = FALSE, tidy = TRUE}
summary(summary(priceModel_enhanced)$residuals)
```
Minimum, maximum and other values represent value of error that can occur in the model.
Residuals explain how well the model is fits the data. Residuals should be symmetrically distributed around 0. Visualizing the residual plot.

```{r echo=FALSE, warning=FALSE, tidy=TRUE}
ggplot(data=train.data, aes(priceModel_enhanced$residuals)) +
  geom_histogram(binwidth = 1, color = "black", fill = "purple4") +
  theme(panel.background = element_rect(fill = "white"),
        axis.line.x=element_line(),
        axis.line.y=element_line()) +
  ggtitle("Histogram for Model Residuals")
```
Histogram shows that residuals are evenly distributed around 0 and hence model is a good fit.

### Comparing three models using RMSE
The RMSE is the square root of the variance of the residuals.</br>
Lower values of RMSE indicate better fit. RMSE is a good measure of how accurately the model predicts the response, and it is the most important criterion for fit if the main purpose of the model is prediction.

```{r include=FALSE, warning = FALSE, tidy = TRUE}
rSquare6 <- sqrt(sum(priceModel$residuals^2) / priceModel$df)
rSquare7 <- sqrt(sum(priceModel_step$residuals^2) / priceModel_step$df)
rSquare8 <- round(sqrt(sum(priceModel_enhanced$residuals^2) / priceModel_enhanced$df),3)
```
Enhanced model has the least RMSE value**(`r rSquare8`)** and is best in predicting House prices.


### Predicting prices

```{r echo=TRUE, warning = FALSE, tidy = TRUE}
predictPrice <- predict(priceModel_enhanced, test.data)
```


#### Plot Actual vs Predicted
Plot of actual vs predicted house prices represent how well the model performed in predicting house prices of test data set.
```{r echo=FALSE, warning = FALSE, tidy = TRUE}
ggplot(data = test.data, aes(x = predictPrice, y = test.data$Y_HousePrice)) +
  geom_point()  +
  stat_smooth(method = "lm", col = "dodgerblue3") +
  theme(panel.background = element_rect(fill = "white"),
        axis.line.x=element_line(),
        axis.line.y=element_line()) +
  ggtitle("Linear Model Fitted to Data") +
  ylab("Actual Price") + 
  xlab("Predicted  Price")

```
</br>Model was able to predict house prices, there were some variations in the predictions but model 


#### Evaluting residual plots for the model to analyse the fit
```{r echo=FALSE, warning = FALSE, tidy = TRUE}
layout(matrix(1:4,2,2)) # to display at once
plot(priceModel_enhanced)
```

<b>Residuals Vs Fittedc</b>  - Residuals are randomly distributed around horizontal line, no distinct trend in distribution is seen. <br>
<b>Normal QQ</b> - Residuals follow straight line with few exceptions and hence can be considered as normally distributed. <br>
<b>Scale Location</b> - Residuals are equally distributed along range of predictors. Hence homoscedasity is there.<br>
<b>Residuals vs Leverage</b> - No points exist on top right or bottom right corner i.e points with distance greater than 1 and hence model is good fit.<br>